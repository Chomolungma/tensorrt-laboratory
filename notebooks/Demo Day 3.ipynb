{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import wurlitzer\n",
    "\n",
    "import infer\n",
    "import infer_test_utils as utils\n",
    "\n",
    "# this allows us to capture stdout and stderr from the backend c++ infer-runtime\n",
    "display_output = wurlitzer.sys_pipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&& RUNNING TensorRT.trtexec # trtexec --onnx=/work/models/onnx/mnist-v1.3/model.onnx --saveEngine=/tmp/mnist-v1.3.engine\n",
      "[I] onnx: /work/models/onnx/mnist-v1.3/model.onnx\n",
      "[I] saveEngine: /tmp/mnist-v1.3.engine\n",
      "----------------------------------------------------------------\n",
      "Input filename:   /work/models/onnx/mnist-v1.3/model.onnx\n",
      "ONNX IR version:  0.0.3\n",
      "Opset version:    8\n",
      "Producer name:    CNTK\n",
      "Producer version: 2.5.1\n",
      "Domain:           ai.cntk\n",
      "Model version:    1\n",
      "Doc string:       \n",
      "----------------------------------------------------------------\n",
      "[I] [TRT] Detected 1 input and 1 output network tensors.\n",
      "[I] Engine has been successfully saved to /tmp/mnist-v1.3.engine\n",
      "[I] name= Input3, bindingIndex=0, buffers.size()=2\n",
      "[I] name= Plus214_Output_0, bindingIndex=1, buffers.size()=2\n",
      "[I] Average over 10 runs is 0.0661504 ms (host walltime is 0.108504 ms, 99% percentile time is 0.09216).\n",
      "[I] Average over 10 runs is 0.0647168 ms (host walltime is 0.109349 ms, 99% percentile time is 0.0768).\n",
      "[I] Average over 10 runs is 0.0626688 ms (host walltime is 0.110325 ms, 99% percentile time is 0.067584).\n",
      "[I] Average over 10 runs is 0.0626688 ms (host walltime is 0.108552 ms, 99% percentile time is 0.067584).\n",
      "[I] Average over 10 runs is 0.064 ms (host walltime is 0.107972 ms, 99% percentile time is 0.07168).\n",
      "[I] Average over 10 runs is 0.062976 ms (host walltime is 0.106543 ms, 99% percentile time is 0.06656).\n",
      "[I] Average over 10 runs is 0.0628736 ms (host walltime is 0.106725 ms, 99% percentile time is 0.06656).\n",
      "[I] Average over 10 runs is 0.0622592 ms (host walltime is 0.10628 ms, 99% percentile time is 0.065536).\n",
      "[I] Average over 10 runs is 0.0633856 ms (host walltime is 0.103612 ms, 99% percentile time is 0.06656).\n",
      "[I] Average over 10 runs is 0.0630752 ms (host walltime is 0.10648 ms, 99% percentile time is 0.06656).\n",
      "&&&& PASSED TensorRT.trtexec # trtexec --onnx=/work/models/onnx/mnist-v1.3/model.onnx --saveEngine=/tmp/mnist-v1.3.engine\n"
     ]
    }
   ],
   "source": [
    "!trtexec --onnx=/work/models/onnx/mnist-v1.3/model.onnx --saveEngine=/tmp/mnist-v1.3.engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remote Inference Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "I0118 05:23:14.588073  1233 inference_manager.cc:64] -- Initialzing TensorRT Resource Manager --\n",
      "I0118 05:23:14.588090  1233 inference_manager.cc:65] Maximum Execution Concurrency: 2\n",
      "I0118 05:23:14.588094  1233 inference_manager.cc:66] Maximum Copy Concurrency: 4\n"
     ]
    }
   ],
   "source": [
    "with display_output():\n",
    "    manager = infer.InferenceManager(max_exec_concurrency=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0118 05:23:17.029314  1233 model.cc:91] Binding: Input3; isInput: true; dtype size: 4; bytes per batch item: 3136\n",
      "I0118 05:23:17.029340  1233 model.cc:91] Binding: Plus214_Output_0; isInput: false; dtype size: 4; bytes per batch item: 40\n",
      "I0118 05:23:17.030128  1233 inference_manager.cc:149] -- Registering Model: mnist --\n",
      "I0118 05:23:17.030139  1233 inference_manager.cc:150] Input/Output Tensors require 3.1 KiB\n",
      "I0118 05:23:17.030145  1233 inference_manager.cc:151] Execution Activations require 55.5 KiB\n",
      "I0118 05:23:17.030149  1233 inference_manager.cc:155] Weights require 23.6 KiB\n"
     ]
    }
   ],
   "source": [
    "with display_output():\n",
    "    manager.register_tensorrt_engine(\"mnist\", \"/tmp/mnist-v1.3.engine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0118 05:23:17.041527  1233 inference_manager.cc:194] -- Allocating TensorRT Resources --\n",
      "I0118 05:23:17.041538  1233 inference_manager.cc:195] Creating 2 TensorRT execution tokens.\n",
      "I0118 05:23:17.041541  1233 inference_manager.cc:196] Creating a Pool of 4 Host/Device Memory Stacks\n",
      "I0118 05:23:17.041548  1233 inference_manager.cc:197] Each Host Stack contains 32.0 KiB\n",
      "I0118 05:23:17.041551  1233 inference_manager.cc:198] Each Device Stack contains 128.0 KiB\n",
      "I0118 05:23:17.041555  1233 inference_manager.cc:199] Total GPU Memory: 768.0 KiB\n"
     ]
    }
   ],
   "source": [
    "with display_output():\n",
    "    manager.update_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with display_output():\n",
    "    manager.serve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
